"""
Test regressions with fixed seed
expected files are in the "expected" folder
the filename has pattern pop_{n}_seed{seed}.json

Expected files are generated by running this script with remove_files = False
and then copying the .json file(s) into the tests/expected folder.
"""

import unittest
import os
import shutil
import sys
import tempfile
import sciris as sc
import synthpops as sp
import inspect
from scipy.spatial import distance
from examples import plot_age_mixing_matrices
try:
    from fpdf import FPDF
except Exception as E:
    print(f'Note: could not import fpdf, report not available ({E})')


# Whether to remove temporary files generated in the process
remove_files = True

class TestRegression(unittest.TestCase):

    @classmethod
    def setUpClass(cls):
        cls.resultdir = tempfile.TemporaryDirectory().name
        cls.figDir = os.path.join(cls.resultdir, "figs")
        cls.configDir = os.path.join(cls.resultdir, "configs")
        cls.pdfDir = os.path.join(os.path.dirname(__file__), "report")
        os.makedirs(cls.pdfDir, exist_ok=True)
        os.makedirs(cls.figDir, exist_ok=True)
        os.makedirs(cls.configDir, exist_ok=True)

    @classmethod
    def tearDownClass(cls):
        if remove_files:
            shutil.rmtree(cls.resultdir, ignore_errors=True)
        else:
            print(f'Results folder: {cls.resultdir}')
            print('Automatic file removing is switched off;\nwhen you are done, please remove it manually')

    def test_regression_make_population(self):
        #set params, make sure name is identical to param names
        n = 2001
        rand_seed = 1001
        max_contacts = None
        with_industry_code = False
        with_facilities = False
        use_two_group_reduction = False
        average_LTCF_degree = 20
        generate = True
        #
        test_prefix = sys._getframe().f_code.co_name
        filename = os.path.join(self.resultdir,f'pop_{n}_seed{rand_seed}.json')
        actual_vals = locals()
        pop = self.runpop(filename=filename, actual_vals=actual_vals, testprefix=test_prefix)
        # if default sort order is not concerned:
        # pop = dict(sorted(pop.items(), key=lambda x: x[0]))

        sc.savejson(filename, pop, indent=2)
        unchanged = self.check_result(actual_file=filename, prefix=test_prefix)
        if unchanged:
            print(f'Note: regression unchanged')
        else:
            print(f'Warning, regression changed! Generating report...')
            self.generate_reports()
            newfilename = os.path.join(self.pdfDir, "new_" + os.path.basename(filename))
            expectedfilename = os.path.join(os.path.dirname(__file__), "expected", os.path.basename(filename))
            shutil.copyfile(filename, newfilename)
            errormsg = f"regression test detected changes, please go to \n{self.pdfDir} " \
                  f"to review contact matrix report \n and compare {expectedfilename} \nwith {newfilename} " \
                  f"\n\nreplace expected {expectedfilename} \nwith {newfilename} \n if you approve this change."
            raise ValueError(errormsg)

    def runpop(self, filename, actual_vals, testprefix = "test", method=sp.make_population):
        # if default sort order is not concerned:
        # pop = dict(sorted(pop.items(), key=lambda x: x[0]))
        params = {}
        args = inspect.getfullargspec(method).args
        for i in range(0, len(args)):
            params[args[i]] = inspect.signature(method).parameters[args[i]].default
        for name in actual_vals:
            if name in params.keys():
                params[name] = actual_vals[name]
        with open(os.path.join(self.configDir, f"{testprefix}.txt"), mode="w") as cf:
            for key, value in params.items():
                cf.writelines(str(key) + ':' + str(value) + "\n")

        pop = method(**params)
        return pop

    def check_result(self, actual_file, expected_file = None, prefix="test"):
        if not os.path.isfile(actual_file):
            raise FileNotFoundError(actual_file)
        if expected_file is None:
            expected_file = os.path.join(os.path.join(os.path.dirname(__file__), 'expected'), os.path.basename(actual_file))
        if not os.path.isfile(expected_file):
            raise FileNotFoundError(expected_file)
        expected = self.cast_uid_toINT(sc.loadjson(expected_file))
        actual = self.cast_uid_toINT(sc.loadjson(actual_file))
        #self.check_similarity(actual, expected)
        if expected == actual:
            #if data are not changed, no report will be generated
            print("nothing changed, skip reporting...")
            return True
        # generate the figures for comparison
        for code in ['H', 'W', 'S']:
            for type in ['density', 'frequency']:
                fig = plot_age_mixing_matrices.test_plot_generated_contact_matrix(setting_code=code,
                                                                                  population=expected,
                                                                                  title_prefix="Baseline_",
                                                                                  density_or_frequency=type)
                #fig.show()
                fig.savefig(os.path.join(self.figDir,f"{prefix}_{code}_{type}_expected.png"))
                fig = plot_age_mixing_matrices.test_plot_generated_contact_matrix(setting_code=code,
                                                                                  population=actual,
                                                                                  title_prefix="Actual_",
                                                                                  density_or_frequency=type)
                #fig.show()
                fig.savefig(os.path.join(self.figDir,f"{prefix}_{code}_{type}_actual.png"))
        return False

    def generate_reports(self):
        #search for config files
        configs = [f for f in os.listdir(self.configDir) if os.path.isfile(os.path.join(self.configDir, f)) and f.endswith(".txt")]
        for c in configs:
            pdf = FPDF()
            pdf.add_page()
            pdf.set_font("Arial", size=12)
            name = os.path.splitext(c)[0]
            contents = ""
            #pdf.cell(w=200, h=10, txt=name, align="C")
            with open(os.path.join(self.configDir, c)) as cf:
                contents = "\n".join([line.strip() for line in cf])
            print(contents)
            pdf.multi_cell(w=100, h=5, txt=contents)
            for code in ['H', 'W', 'S']:
                for type in ['density', 'frequency']:
                    pdf.add_page()
                    figs = [f for f in os.listdir(self.figDir) if f.startswith(f"{name}_{code}_{type}")]
                    for ff in figs:
                        #print(ff)
                        pdf.image(os.path.join(self.figDir, ff), w=100, h=100)
            pdf.output(os.path.join(self.pdfDir,f"{name}.pdf"))

    def check_similarity(self, actual, expected):
        """
        Compare two population dictionaries using contact matrix
        Assuming the canberra distance should be close to zero
        """
        for code in ['H', 'W', 'S']:
            for option in ['density', 'frequency']:
                print(f"\ncheck:{code} with {option}")
                actual_matrix = sp.calculate_contact_matrix(actual, density_or_frequency=option, setting_code=code)
                expected_matrix = sp.calculate_contact_matrix(expected, density_or_frequency=option, setting_code=code)
                # calculate Canberra distance
                # assuming they should round to 0
                d = distance.canberra(actual_matrix.flatten(), expected_matrix.flatten())
                self.assertEqual(round(d), 0, f"actual distance for {code}/{option} is {str(round(d))}, "
                                              f"you need to uncommented line 55 to plot the density matrix and investigate!")

    def cast_uid_toINT(self, dict):
        return {int(key): val for key, val in dict.items()}


# Run unit tests if called as a script
if __name__ == '__main__':
    unittest.main()